{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8473d8f8-1674-4caf-bd10-df33de60fdc5",
   "metadata": {},
   "source": [
    "# CSCI 632 Homework 5"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4b3a307a-7fff-44cc-bf5c-8b3b205593c5",
   "metadata": {},
   "source": [
    "**Instructions**\n",
    "\n",
    "* **Insert all code, plots, results, and discussion** into this Jupyter Notebook.\n",
    "* Your homework should be submitted as a **single Jupyter Notebook** (.ipynb file).\n",
    "* While working, you use Google Colab by uploading this notebook and performing work there. Once complete, export the notebook as a Jupyter Notebook (.ipynb) and submit it to **Blackboard.**\n",
    "\n",
    "You can answer mathematical questions either by:\n",
    "* using LaTeX in a markdown cell, or\n",
    "* pasting a scanned or photographed handwritten answer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dcfd286-f8ec-4ce6-9411-1d57d8cf805d",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 1: Confusion for a Dog Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee2236e",
   "metadata": {},
   "source": [
    "You are given a set of **10 binary classification results**.  \n",
    "Each prediction determines whether the image is a **Dog** üê∂ or **Not Dog** üê±üêªüê∞ü¶äüêÆ.  \n",
    "Fill in the final column with `TP`, `FP`, `TN`, or `FN`.\n",
    "\n",
    "| # | üñºÔ∏è Sample | **Actual Class** | **Predicted Class** | **Category (TP / FP / TN / FN)** |\n",
    "|:-:|:-----------:|:----------------:|:-------------------:|:--------------------------------:|\n",
    "| 1 | üê∂ | Dog | Dog | |\n",
    "| 2 | üê± | Not Dog | Not Dog | |\n",
    "| 3 | üêª | Not Dog | Not Dog | |\n",
    "| 4 | üê∂ | Dog | Not Dog | |\n",
    "| 5 | üê∞ | Not Dog | Dog | |\n",
    "| 6 | üê∂ | Dog | Not Dog | |\n",
    "| 7 | ü¶ä | Not Dog | Not Dog | |\n",
    "| 8 | üê∂ | Dog | Dog | |\n",
    "| 9 | üêÆ | Not Dog | Not Dog | |\n",
    "| 10 | üê∂ | Dog | Not Dog | |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ec8e2f",
   "metadata": {},
   "source": [
    "\n",
    "**Problem 1(b)**. Tally the totals for **TP**, **FP**, **TN**, and **FN**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b713e2",
   "metadata": {},
   "source": [
    "**Problem 1(c)**. Construct a **confusion matrix** by entering the sample number\n",
    "for each sample in the appropriate quadrant of the matrix.\n",
    "\n",
    "|                     | **Predicted: Positive** | **Predicted: Negative** |\n",
    "|---------------------:|:-----------------------:|:-----------------------:|\n",
    "| **Actual: Positive** | <br><br> | <br><br> |\n",
    "| **Actual: Negative** | <br><br> | <br><br> |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460193b7",
   "metadata": {},
   "source": [
    "\n",
    "**Problem 1(d)** Compute:\n",
    "   - **Precision = TP / (TP + FP)**  \n",
    "   - **Recall = TP / (TP + FN)**  \n",
    "   - **Accuracy = (TP + TN) / Total**\n",
    "   - **F‚ÇÅ Score**\n",
    "\n",
    "**Problem 1(e)** Assuming these samples were drawn randomly from a population of\n",
    "animal pictures, what is the estimated class prior probability for the dog class?\n",
    "\n",
    "**Problem 1(f)** Is this data set balanced? \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67781b40",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 2: Confusion for a Cat Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b33f4b1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "This classifier tries to detect **cats üê±** \n",
    "\n",
    "You have 100 samples of which 98 are cats.  The other 2 are dogs.\n",
    "The classifier says there are 100 cats and no dogs.\n",
    "\n",
    "**Problem 2(a)** What are the accuracy, recall, and precision of this classifier?\n",
    "\n",
    "**Problem 2(b)** Is this a good classifier?  Why or why not?\n",
    "\n",
    "**Problem 2(c)** Is this a balanced data set?\n",
    "\n",
    "**Problme 2(d)** What is the $F_1$ metric for this classifer?\n",
    "\n",
    "**Problem 2(e)** If you want a single metric that does not measure the bias\n",
    "towards either precision or recall would you choose $F_1$ or accuracy?  Why?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab5e03ac",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 3: Optimal Classifier with Respect to Error\n",
    "\n",
    "An optimal classifier does not necessarily achieve zero error.  \n",
    "Sometimes there is **inherent ambiguity** ‚Äî the same feature vector \n",
    "$x$ can occur for more than one class.  The optimal classifier \n",
    "always chooses the class with the highest posterior \n",
    "probability $P(\\omega_i \\mid x)$.\n",
    "\n",
    "Consider a one-dimensional feature variable $x \\in [0,1]$.  \n",
    "There are two classes, $\\omega_1$ and $\\omega_2$, and the prior\n",
    "probabilities are equal:\n",
    "\n",
    "$$\n",
    "P(\\omega_1) = P(\\omega_2) = \\tfrac{1}{2}.\n",
    "$$\n",
    "\n",
    "The conditional probabilities $P(\\omega_1 \\mid x)$ and \n",
    "$P(\\omega_2 \\mid x)$ vary across three regions:\n",
    "\n",
    "$$\n",
    "P(\\omega_1 \\mid x) =\n",
    "\\begin{cases}\n",
    "1, & 0 \\le x < \\tfrac{1}{3} \\quad \\text{(Region A)} \\\\\n",
    "2 - 3x, & \\tfrac{1}{3} \\le x \\le \\tfrac{2}{3} \\quad \\text{(Region B)} \\\\\n",
    "0, & \\tfrac{2}{3} < x \\le 1 \\quad \\text{(Region C)}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "P(\\omega_2 \\mid x) = 1 - P(\\omega_1 \\mid x).\n",
    "$$\n",
    "\n",
    "Assume that $x$ is uniformly distributed on $[0,1]$.\n",
    "\n",
    "**(a)** Sketch or plot $P(\\omega_1 \\mid x)$ and $P(\\omega_2 \\mid x)$ versus $x$.  \n",
    "Label the three regions $A$, $B$, and $C$.\n",
    "\n",
    "**(b)** Write the Bayes decision rule for minimizing the probability of error:\n",
    "\n",
    "$$\n",
    "\\text{Decide } \\omega_1 \\text{ if } P(\\omega_1 \\mid x) > P(\\omega_2 \\mid x), \\text{ else decide } \\omega_2.\n",
    "$$\n",
    "\n",
    "The decision rule should ranges of $x$ in which the classifier decides \n",
    "$\\omega_1$ and decides $\\omega_2$ with the precise location of the boundary where the classifier switches.\n",
    "\n",
    "**(c)** Compute the minimum achievable probability of error:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da36c9d4",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 4: Optimal Classification with Three Classes\n",
    "\n",
    "An optimal classifier minimizes the probability of error by choosing the class with the largest posterior probability $P(\\omega_i \\mid x)$. \n",
    "\n",
    "Consider a one-dimensional feature $x \\in [0,1]$ with three classes\n",
    "$\\omega_1, \\omega_2, \\omega_3$.  Assume equal priors\n",
    "$$\n",
    "P(\\omega_1)=P(\\omega_2)=P(\\omega_3)=\\tfrac{1}{3},\n",
    "$$\n",
    "and assume $x$ is uniformly distributed on $[0,1]$.\n",
    "\n",
    "To ensure that **all classes have nonzero probability everywhere**, the posteriors are defined piecewise as follows:\n",
    "\n",
    "For $0 \\le x \\le \\tfrac{1}{2}$,\n",
    "\n",
    "\\begin{align*}\n",
    "P(\\omega_1 \\mid x) &= 0.8 - 1.4x, \\\\\n",
    "P(\\omega_2 \\mid x) &= 0.1 + 1.4x, \\\\\n",
    "P(\\omega_3 \\mid x) &= 0.1.\n",
    "\\end{align*}\n",
    "\n",
    "For $\\tfrac{1}{2} \\le x \\le 1$,\n",
    "\n",
    "\\begin{align*}\n",
    "P(\\omega_1 \\mid x) &= 0.1, \\\\\n",
    "P(\\omega_2 \\mid x) &= 1.5 - 1.4x, \\\\\n",
    "P(\\omega_3 \\mid x) &= 1.4x - 0.6.\n",
    "\\end{align*}\n",
    "\n",
    "These functions are continuous at $x=\\tfrac{1}{2}$, each is in $[0.1, 0.8]$, and\n",
    "$$\n",
    "P(\\omega_1 \\mid x)+P(\\omega_2 \\mid x)+P(\\omega_3 \\mid x)=1 \\quad \\text{for all } x\\in[0,1].\n",
    "$$\n",
    "\n",
    "\n",
    "**(a)** Sketch or plot $P(\\omega_1 \\mid x)$, $P(\\omega_2 \\mid x)$, and $P(\\omega_3 \\mid x)$ over $x \\in [0,1]$.  \n",
    "Label the regions where each class attains the largest posterior.\n",
    "\n",
    "**(b)** Write the Bayes decision rule that minimizes probability of error and determine the decision regions explicitly; i.e., find the boundary point(s) where the predicted class changes.\n",
    "\n",
    "**(c)** Compute the minimum achievable probability of error\n",
    "\n",
    "*Hint:* The probability of error at a given $x$ is \n",
    "$1 - \\max_i P(\\omega_i \\mid x)$, which equals the sum\n",
    "of the posteriors of the **nonselected** classes at that $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5f09e0",
   "metadata": {},
   "source": [
    "---\n",
    "## Problem 5: Risk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c0a07fa",
   "metadata": {},
   "source": [
    "\n",
    "Automatic Content Recognition (ACR) aims to identify content such as TV\n",
    "shows, movies, or sports broadcasts. In this scenario, we treat each piece of\n",
    "content as a class in a multiclass classification problem, where there are\n",
    "$K$ known pieces of content. \n",
    "\n",
    "During distribution, the same content may be re-encoded multiple times to adapt\n",
    "to available bandwidth or loss characteristics, and may be subject to \"visual\n",
    "enhancements\" by devices like set-top boxes or TVs. These modifications\n",
    "introduce noise, but the model must still correctly classify the content.\n",
    "\n",
    "Because video and audio are composed of continuous streams of frames or audio\n",
    "samples, from which we generate feature vectors $\\mathbf{x}(t)$ at different\n",
    "time points $t$, we are not forced to make an immediate decision. Instead, the\n",
    "ACR system can choose to *reject* an observation as unrecognizable, rather than\n",
    "risk misclassifying it. When the cost of rejection is low, it may be preferable\n",
    "to reject an observation and wait for more data to improve confidence.\n",
    "\n",
    "Let $\\lambda$ denote our loss function.\n",
    "\n",
    "\\begin{equation}\n",
    "\\lambda(\\alpha_i| \\omega_j) =\n",
    "\\begin{cases}\n",
    "  0 & i = j \\text{ for } i, j = 1, ..., K \\\\\n",
    "  \\lambda_r & i = K + 1 \\quad (\\text{rejection}) \\\\\n",
    "  \\lambda_s & \\text{if } i \\neq j \\quad (\\text{substitution}) \n",
    "\\end{cases}\n",
    "\\end{equation}\n",
    "\n",
    "where \n",
    "\n",
    "* $\\lambda_r$ is the loss incurred for rejecting the observation\n",
    "  (i.e., deciding to wait).  Let action $(K+1)$ denote rejection.\n",
    "* $\\lambda_s$ is the loss incurred for a substitution error (i.e.,\n",
    "  classifying the observation as the wrong content).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32627a1",
   "metadata": {},
   "source": [
    "**(a)** At decision time, the ACR system must either choose to classify the content into one of the known classes or reject the observation (i.e., postpone the decision). Find the risk function for the case where the system chooses to classify the observation (i.e., no rejection), $R(\\alpha_i | \\mathbf{x}, \\text{choose})$. The risk function represents the expected loss conditioned on the observation $\\mathbf{x}$ and the decision to classify."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7551d94",
   "metadata": {},
   "source": [
    "**(b)** If the risk of classifying the content (i.e., choosing) exceeds the\n",
    "risk of rejecting the observation, then choosing will increase the overall\n",
    "risk. To minimize the risk, we should only choose to classify if:\n",
    "\n",
    "$$R(\\alpha_i|\\mathbf{x}, \\text{choose}) \\leq R(\\alpha_i|\\mathbf{x}, \\text{reject})$$\n",
    "\n",
    "Using this criterion, show that the minimum risk is obtained by classifying\n",
    "the observation as class $\\omega_i$ if:\n",
    "\n",
    "$$P(\\omega_i|\\mathbf{x}) \\geq P(\\omega_j|\\mathbf{x}) \\text{ for all } j \\neq i$$\n",
    "which means choosing the class with the highest posterior probability.\n",
    "Furthermore, show that we should classify the observation as $\\omega_i$ if\n",
    "\n",
    "$$P(\\omega_i | \\mathbf{x}) \\geq 1 - \\frac{\\lambda_r}{\\lambda_s}, $$\n",
    "\n",
    "and reject otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a7f451",
   "metadata": {},
   "source": [
    "**(c)** What happens to the decisions made when $\\lambda_r = 0$?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1312703",
   "metadata": {},
   "source": [
    "**(d)** What happens to the decisions made when $\\lambda_r > \\lambda_s$?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
