{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4269600",
   "metadata": {},
   "source": [
    "# CSCI632 Homework 2: More Linear Algebra Review for Deep Learning\n",
    "\n",
    "### Instructions\n",
    "This assignment is designed to review key linear algebra concepts used throughout *Deep Learning* (Goodfellow et al., Ch. 2).\n",
    "It expands on homework 1.  It emphasizes manipulation of matrices, vector spaces, dependence/independence, and norms.\n",
    "Show all steps and justify each answer.   You do not need to use LaTeX for these answers.  \n",
    "\n",
    "\n",
    "## Deliverables\n",
    "- A jupyter notebook, scanned image, or PDF of your typed, LaTeX, or handwritten solutions.\n",
    "- For conceptual questions, write concise but clear explanations.\n",
    "- For computational problems, show all steps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba741ea-115d-42d2-a213-6ae2dc82e89f",
   "metadata": {},
   "source": [
    "## Part A. Watch videos\n",
    "\n",
    "I believe 3Blue 1Brown has some of the best vides for visualizing linear algebra, so much so that I want you to watch them.  If you know the material, do it a 2x speed, or just watch enough to answer the questions below.\n",
    "\n",
    "For each of the following videos provide a few sentences describing the content of the video.\n",
    "\n",
    "### Linear combinations, span, and basis vectors | Chapter 2, Essence of linear algebra\n",
    "\n",
    "https://www.youtube.com/watch?v=k7RM-ot2NWY&list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab&index=2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe9251f-5c95-40c0-b5fb-a6c5f77d30b1",
   "metadata": {},
   "source": [
    "**Answer**: This video provides visualizations of basis vectors and how we can represent vectors as linear\n",
    "combinations of these basis vectors.  The set of all vectors created as a linear combination \n",
    "of the basis vectors is the *span* of the basis vectors.  The video then introduces the notion \n",
    "of linear independence between vectors.\n",
    "\n",
    "**Gradine note**: Any answer that mentions that the video presents vectors, basis\n",
    "vectors, span, and linear independence is sufficient."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d0131e-379c-48f0-9133-8864af3be43b",
   "metadata": {},
   "source": [
    "\n",
    "### Linear transformations and matrices | Chapter 3\n",
    "\n",
    "https://www.youtube.com/watch?v=kYB8IZa5AuE&list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab&index=3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645e5579-6e6e-4ef9-80d2-8535d3569311",
   "metadata": {},
   "source": [
    "**Possible Answer**\n",
    "\n",
    "A transformation is a function that maps between an input and an output vector \n",
    "space. The video invites the viewer to think of a *transformation* as motion — \n",
    "taking in an input vector and moving it to an output vector. The video illustrates \n",
    "cases such as rotation, scaling, shearing, and reflection. These illustrate \n",
    "*linear transformations*.  \n",
    "\n",
    "Consider the case where the input space is two-dimensional. Then the set of all \n",
    "input vectors can be represented as an infinite plane, which we can visualize as \n",
    "a uniform grid. A linear transformation maps the grid so that:  \n",
    " * the origin remains fixed,  \n",
    " * straight lines remain straight,  \n",
    " * parallel lines remain parallel, and  \n",
    " * points evenly spaced along a line remain evenly spaced (though the distances may be stretched or squashed).  \n",
    "\n",
    "The video then proceeds to discuss how we can represent the columns of a matrix as being\n",
    "coordinates where the unit vectors would be mapped.  The transformation maps $\\hat{i}$ \n",
    "to column 1.  The transform maps $\\hat{j}$ to column 2 and so on.  For example, we\n",
    "represent $\\hat{i}$ with the column vector\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "1 \\\\ \n",
    "0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "For example:\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "  1 & 3 \\\\\n",
    " -2 & 0 \n",
    "\\end{bmatrix} \n",
    "\\begin{bmatrix}\n",
    "  1 \\\\ \n",
    "  0\n",
    "\\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "  1 \\\\ \n",
    " -2\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "which is exactly the first column of the matrix. Similarly, multiplying by \n",
    "$\\hat{j}$ selects the second column, showing where $\\hat{j}$ lands under the \n",
    "transformation.  \n",
    "\n",
    "**Grading note:** Any answer that discusses the definition and properties of linear transformations is acceptable. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01950973-413c-43f3-914c-f22c8a396601",
   "metadata": {},
   "source": [
    "### Matrix multiplication as composition | Chapter 4, Essence of linear algebra\n",
    "\n",
    "https://www.youtube.com/watch?v=XkY2DOUCWMU&list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab&index=4\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0097e069-c46f-4785-8b7d-20a5cc1b4dc2",
   "metadata": {},
   "source": [
    "**Possible Answer** The video represents multiplying by two linear transformations as a composition.\n",
    "\n",
    "To find the effect of $AB$ where $A$ and $B$ are $2\\times 2$ matrices, we \n",
    "track how $A$ and $B$ would move the basis vectors\n",
    "$\\hat{i}$ and $\\hat{j}$.  Let's start with how $\\hat{i}$ is affected: $AB\\hat{i}$.\n",
    "I first perform $B\\hat{i}$ where the first column tells me where $\\hat{i}$ goes.  \n",
    "Let $\\hat{i}'$ denote the transformed unit vector $\\hat{i}$. I can then apply $A$ to show \n",
    "where $\\hat{i}'$ moves to get $\\hat{i}''$.  I can then do \n",
    "the same operation for $AB\\hat{j}$ to get $\\hat{j}''$.   The resulting locations of \n",
    "$\\hat{i}''$ gives me column 1 and $\\hat{j}''$ gives me column 2 of the combined matrix\n",
    "$C = AB$. \n",
    "\n",
    "After showing this example, the video replaces the integers in the $2 \\times 2$ matices with letters.\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "a & b \\\\\n",
    "c & d\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "e & f \\\\\n",
    "g & h\n",
    "\\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "a e + b g & a f + b h \\\\\n",
    "c e + d g & c f + d h\n",
    "\\end{bmatrix}\n",
    "$$ \n",
    "\n",
    "The video then demonstrates visually why matrix multplication is not commutative using a shear\n",
    "and rotation versus the same rotation and then the same shear.  It easy to come up\n",
    "with examples where commutivity fails.  Here is one not used in the video.\n",
    "Use your right hand.  Turn it palm upward. Use your thumb as the $x$ axis and extend your\n",
    "index finger in the $y$ direction.  It is now your $y$ axis.\n",
    "\n",
    "**Grading note:** Any answer that discusses the performing matrix \n",
    "multiplication involving more than one matrix is sufficient. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff6ffa1-9606-44ac-8121-5d8bbca84a51",
   "metadata": {},
   "source": [
    "### The determinant | Chapter 6, Essence of linear algebra\n",
    "\n",
    "https://www.youtube.com/watch?v=Ip3X9LOh2dk&list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab&index=6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2a0283-a585-4b8d-9f02-d1421a185b31",
   "metadata": {},
   "source": [
    "**Possible Answer** \n",
    "\n",
    "To visualize the determinant let's start in two dimensions.  Consider the unit vectors\n",
    "$\\hat{i}$ and $\\hat{j}$.  Visualize these as the edges of a square.  The area of this square\n",
    "is equal to the base times the height.  Since the unit vectors both have length 1, the area\n",
    "of the square bordered by $\\hat{i}$ and $\\hat{j}$ is also 1.\n",
    "\n",
    "The determinant can be viewed as how much the transformation scales this area.\n",
    "If my transformation scales $\\hat{i}$ to a length of 2 but keeps $\\hat{j}$ the\n",
    "same, I now have column vectors\n",
    "\n",
    "$$\n",
    "2\\hat{i} = \n",
    "  \\begin{bmatrix}\n",
    "    2 \\\\\n",
    "    0 \n",
    "  \\end{bmatrix}, \n",
    "\\hat{j} = \n",
    "  \\begin{bmatrix}\n",
    "    0 \\\\\n",
    "    1\n",
    "  \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Now consider the rectangle with $2\\hat{i}$ along the base and $\\hat{j}$ along the left edge.\n",
    "The resulting area is $2 \\times 1 = 2.$.  If we represent the matrix by how it changes\n",
    "the $\\hat{i}$ and $\\hat{j}$ basis vectors as was shown in previous videos, we \n",
    "put the result of the transformation of $\\hat{i}$ in the left column and $\\hat{j}$ in the right.\n",
    "\n",
    "$$\n",
    "A = \\begin{bmatrix}\n",
    "  2 & 0 \\\\\n",
    "  0 & 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Because this transformation scales the area of the square with edges $\\hat{i}$ and $\\hat{j}$\n",
    "by a factor of 2, we say that matrix $A$ has a determinant of 2.\n",
    "\n",
    "The video shows the example of transformation that introduces a shear\n",
    "\n",
    "$$\n",
    "B = \\begin{bmatrix}\n",
    "  1 & 1 \\\\\n",
    "  0 & 1 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "As mentioned already, from the prior videos we can think of the left column\n",
    "as the location where $\\hat{i}$ would end up and the right column of where\n",
    "$\\hat{j}$ would end up.  Thus $\\hat{i}$ remains at $(1, 0)$ and is \n",
    "thus unaffected, but the second basis vector moves from $\\hat{j}$ to $(1, 1)$.\n",
    "It tilts my entire output space to the right by 45 degrees without affecting\n",
    "the x direction.   This is an example of a *shear.* In general a shear\n",
    "can tilt the y-axis by any amount as defined by the number in the upper-righthand\n",
    "corner of the $2 \\times 2$ matrix.  Or we could shear by tilting only\n",
    "the x-axis by leaving the upper-righthand corner zero while changing the \n",
    "lower-lefthand corner of the matrix.\n",
    "\n",
    "The resulting area with edges represented by vectors from the origin $(0,1)$\n",
    "and $(1,1)$ is a parallelogram.  The area of a parallelogram is still the\n",
    "base times the height so the area after the linear transformation $B$ still\n",
    "remains 1.   We say thus that $B$ has a determinant of 1.\n",
    "\n",
    "The video generalizes this concept to any arbitrary area.  If a linear\n",
    "transformation would scale a unit square by a factor of 2 then it would scale\n",
    "ANY region's area by a factor of 2, because linear transformations always\n",
    "keep the grid lines on the input space parallel and evenly spaced in the\n",
    "output space.\n",
    "\n",
    "There is an important detail that I glossed over: determinants can be\n",
    "negative.  A negative area does not make sense, but in the case of\n",
    "determinants the sign signifies orientation.   A positive determinant\n",
    "means the linear transformation preserves a counterclockwise orientation:\n",
    "$\\hat{j}$ maps to a location that is counterclockwise from\n",
    "where $\\hat{i}$ maps to. This could be precisely stated as \"the image of $\\hat{j}$\n",
    "lies counterclockwise from the image of $\\hat{i}$.\" A negative determinant\n",
    "means that $\\hat{j}$ ends up clockwise from $\\hat{i}$. \n",
    "\n",
    "If a linear transformation maps $\\hat{i}$ and $\\hat{j}$ onto a line\n",
    "then the area of the resulting parallelogram is 0.  For\n",
    "example, if matrix $C$ maps $\\hat{i}$ to $(2,1)$ and $\\hat{j}$ to \n",
    "$(4,2)$ then we have the matrix\n",
    "\n",
    "$$\n",
    "C = \\begin{bmatrix}\n",
    "  2 & 4 \\\\\n",
    "  1 & 2\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "If we consider the left column to be one basis vector and the right column\n",
    "to be the second basis vector, we see both point in the same direction.\n",
    "The span of these vectors is a line.\n",
    "\n",
    "All matrices with a determinant of zero correspond to mapping\n",
    "of the unit square to a region with zero area, but not all\n",
    "matrices with a determinant of zero span a space with the same \n",
    "dimensionality.   $C$ has a determinant of 0, but it maps to a line.\n",
    "If both column vectors are the zero vector then the matrix has a \n",
    "zero determinant but it maps the entire input space onto the origin, \n",
    "i.e., a single point.\n",
    "\n",
    "The determinant can be computed mechanically by doing the following:\n",
    "\n",
    "$$\n",
    "\\textrm{det}\\left( \n",
    "  \\begin{bmatrix}\n",
    "    a & b \\\\\n",
    "    c & d\n",
    "  \\end{bmatrix}\n",
    "\\right) = ad - bc\n",
    "$$\n",
    "\n",
    "The video ends with a geometric illustration as to how the determinant\n",
    "represents the area of the parallelogram with two edges defined by the basis \n",
    "vectors taken relative to the origin, by subtracting regions away \n",
    "from the rectangle with edges of length $a+b$ and $c+d$.\n",
    "\n",
    "$$\n",
    "(a+b)(c+d) - ac - bd - 2bc = ad-bc\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04c41d6",
   "metadata": {},
   "source": [
    "**Grading note:** Any answer that discusses how determinant \n",
    "is a measure of the area of the region with the basis vectors\n",
    "as edges of this area, and what it means to have a negative \n",
    "determinant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8471f0b0-26ed-42f1-bbc4-7494bd530201",
   "metadata": {},
   "source": [
    "### Inverse matrices, column space and null space | Chapter 7, Essence of linear algebra\n",
    "\n",
    "\n",
    "https://www.youtube.com/watch?v=uQhTuRlWMxw&list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab&index=7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f7e925-e535-45d8-933c-cbdea11572a6",
   "metadata": {},
   "source": [
    "**Possible Answer** \n",
    "\n",
    "This video starts by describing the representation of systems of linear equations\n",
    "using matrices.\n",
    "\n",
    "$$A \\mathbf{x} = \\mathbf{v}$$\n",
    "\n",
    "where $A$ is a matrix, $\\mathbf{x}$ is a column vector representing our unknowns\n",
    "and $\\mathbf{v}$ represents where $A$ maps $\\mathbf{x}$.  Given $\\mathbf{v}$ and \n",
    "$A$, we want to find $\\mathbf{x}$.\n",
    "\n",
    "The video then desribes the notion of the identity matrix which is the matrix\n",
    "that is all zeroes except with ones along the diagonal.\n",
    "\n",
    "$$\\begin{bmatrix}\n",
    "1 & 0 & \\cdots & 0 \\\\\n",
    "0 & 1 &        & 0 \\\\\n",
    "\\vdots &  & \\ddots &  \\\\\n",
    "0 & 0 & \\cdots & 1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "The identity matrix leaves a square matrix unchanged:\n",
    "\n",
    "$$AI = IA = A$$\n",
    "\n",
    "It is one case where commutivity holds even though matrix\n",
    "multiplication is not generally commutative.\n",
    "\n",
    "For some square matrices, we can find a matrix $A^{-1}$ such \n",
    "that multiplying $A^{-1}A = AA^{-1} = I$.  We call $A^{-1}$\n",
    "the inverse of $A$.\n",
    "\n",
    "If know the inverse matrix of $A$, finding $\\mathbf{x}$ is trivial.\n",
    "We multiply both sides by $A^{-1}$.\n",
    "\n",
    "$$A^{-1} A \\mathbf{x} = A^{-1} \\mathbf{v}$$\n",
    "\n",
    "which can be rewritten as \n",
    "\n",
    "$$A^{-1} A \\mathbf{x} = I \\mathbf{x} = \\mathbf{x} = A^{-1} \\mathbf{v}$$\n",
    "\n",
    "When the determinant of a matrix is zero, it maps the input space\n",
    "onto lower dimensions.  For two dimension, a matrix with a determinant\n",
    "of zero maps the input space onto a line or a point (the origin).  There is no\n",
    "transformation that maps a line or a point back into a plane.  Thus,\n",
    "a matrix with a determinant of zero has no inverse.\n",
    "\n",
    "Just because there is no inverse matrix of $A$, it does not mean that \n",
    "there exists no solution to \n",
    "\n",
    "$$A \\mathbf{x} = \\mathbf{v}$$\n",
    "\n",
    "In two dimensions it just means there is only a solution if \n",
    "$x$ lies on the line in which one or both of the column \n",
    "vectors of $A$ point(s).  In higher dimensions, the solution\n",
    "must land on the point, line, plane or hyperplane spanned \n",
    "by the column vectors or there is no solution.\n",
    "\n",
    "The video ends by exploring full rank vs. non-full rank matrices\n",
    "and how this relates to the nullspace of a matrix.\n",
    "The nullspace describes all solutions to A $\\mathbf{x} = 0$, and its \n",
    "dimension tells us how far A is from being full rank."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50993db9-f58d-478e-a98b-696568cbe54e",
   "metadata": {},
   "source": [
    "**Possible Answer** \n",
    "\n",
    "A basis is just a set of vectors we choose to describe space.  When we say basis \n",
    "vectors we often think of $\\hat{i}$, $\\hat{j}$, and $\\hat{k}$ if in three\n",
    "dimensions, but space has no intrinsic coordinate system.  In linear algebra,\n",
    "the origin is fixed; when we change the basis, we’re only re-scaling and\n",
    "re-orienting the coordinate axes.\n",
    "\n",
    "Although not mentioned in the video, it is worth pointing out that in physics\n",
    "and engineering, we also often translate the origin, but this is referred to\n",
    "as a change in the *frame of reference*. When discussing a *change of basis*, \n",
    "we keep the origin fixed while scaling and/or reorienting our basis vectors.\n",
    "\n",
    "\n",
    "In the video, Grant Sanderson introduces an alternate basis used by a fictional Jennifer:\n",
    "\n",
    "$$\n",
    "\\mathbf{b_1} = \\begin{bmatrix} 2 \\\\ 1 \\end{bmatrix},\\qquad\n",
    "\\mathbf{b_2} = \\begin{bmatrix} -1 \\\\ 1 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "If a vector has Jennifer’s coordinates $\\mathbf{u} = (-1, 2)$, it's \n",
    "arrow in our coordinate system is\n",
    "\n",
    "$$\n",
    "\\mathbf{x} = -1 \\cdot \\mathbf{b_1} + 2 \\mathbf{b_2} = \n",
    "  -1 \\begin{bmatrix} 2 \\\\ 1 \\end{bmatrix}\n",
    "  + 2 \\begin{bmatrix} -1 \\\\ 1 \\end{bmatrix} \n",
    "  = \\begin{bmatrix} -1 \\cdot 2 + 2 \\cdot (-1) \\\\ (-1) \\cdot 1 + 2 \\cdot 1 \\end{bmatrix}\n",
    "  = \\begin{bmatrix} -4 \\\\ 1 \\end{bmatrix} \\tag{1}\n",
    "$$\n",
    "\n",
    "Writing the basis vectors as columns of a matrix,\n",
    "\n",
    "$$\n",
    "B = \\begin{bmatrix}\n",
    "      2 & -1 \\\\\n",
    "      1 & 1\n",
    "    \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "this is simply\n",
    "\n",
    "$$\n",
    "B \\mathbf{u} = \\begin{bmatrix}\n",
    "  2 & -1 \\\\\n",
    "  1 & 1 \n",
    "\\end{bmatrix} \n",
    "\\begin{bmatrix}\n",
    "  -1 \\\\\n",
    "  2\n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "  -2 - 2 \\\\\n",
    "  -1 + 2\n",
    "\\end{bmatrix} =\n",
    "\\begin{bmatrix} \n",
    "  -4 \\\\\n",
    "   1 \n",
    "\\end{bmatrix} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14caa745-5efd-4961-9fa5-371cbc1e33cc",
   "metadata": {},
   "source": [
    "### Change of basis | Chapter 13, Essence of linear algebra\n",
    "\n",
    "https://www.youtube.com/watch?v=P2LTAUO1TdA&list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab&index=13"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff53dd8",
   "metadata": {},
   "source": [
    "What if we want to go the other direction?  How do we transform a coordinate\n",
    "in our coordinate system to Jennifer's coordinate system?  We use the inverse:\n",
    "\n",
    "$$B^{-1} \\mathbf{x} = B^{-1} B \\mathbf{u} = I \\mathbf{u} = \\mathbf{u}$$\n",
    "\n",
    "A valid basis matrix is 1) square, 2) spans the space with dimensionality equal\n",
    "to the number basis vectors, 3) has non-zero determinant and 4) is invertible.\n",
    "\n",
    "Since $B$ is invertible, we can always convert from our basis $\\hat{i}$, $\\hat{j}$ \n",
    "to the basis represented by $B$ and back.\n",
    "\n",
    "**Grading note:** Any answer that discusses how the column vectors can be intepreted as basis vectors, and that multiplying by a vector by\n",
    "a matrix moves the vector into the basis of the matrix's column vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d4e9fe-af5d-42f9-a05c-91b3239bc24b",
   "metadata": {},
   "source": [
    "### Eigenvectors and eigenvalues | Chapter 14, Essence of linear algebra\n",
    "\n",
    "https://www.youtube.com/watch?v=PFDu9oVAE-g&list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab&index=14"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bda117-85b6-45d6-ba20-89bf84189bcf",
   "metadata": {},
   "source": [
    "Eigenvectors $\\mathbf{v}$ for matrix $A$ are solutions to the equation\n",
    "\n",
    "$$\n",
    "A\\mathbf{v} = \\lambda \\mathbf{v}\n",
    "$$\n",
    "\n",
    "Here $\\lambda$ is a scalar called an eigenvalue.\n",
    "\n",
    "This video presents a particularly intuitive example of eigenvectors.\n",
    "In 3d, consider a linear transformation that performs a rotation.\n",
    "The orientation of the axis of rotation does not change as the \n",
    "space is rotated, nor does the scale of the space and thus $\\lambda=1$.\n",
    "\n",
    "In 2-space, consider the matrix which introduces a shear.\n",
    "\n",
    "$$\n",
    "A = \\begin{bmatrix}\n",
    "  3 & 1 \\\\\n",
    "  0 & 2 \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Now consider any vector on the x-axis.\n",
    "\n",
    "$$\n",
    "\\mathbf{v} = \\begin{bmatrix}\n",
    " a \\\\\n",
    " 0\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Multiplying $A$ by $\\mathbf{v}$ yields\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "  3 & 1 \\\\\n",
    "  0 & 2\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    " a \\\\\n",
    " 0\n",
    " \\end{bmatrix} =\n",
    " a \\begin{bmatrix}\n",
    "    3 \\\\\n",
    "    0\n",
    "   \\end{bmatrix}\n",
    "+ 0 \\begin{bmatrix}\n",
    "    1 \\\\\n",
    "    2\n",
    "   \\end{bmatrix}\n",
    "   = 3 \\begin{bmatrix}\n",
    "       a \\\\\n",
    "       0\n",
    "       \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Thus all vectors $(a,0)$ are eigenvectors with the eigenvalue 3.\n",
    "\n",
    "Another family of eigenvectors are multiples of $(-1,1)$.\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "  3 & 1 \\\\\n",
    "  0 & 2\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    " -b \\\\\n",
    " b\n",
    " \\end{bmatrix} =\n",
    "- b \\begin{bmatrix}\n",
    "      3 \\\\\n",
    "      0\n",
    "    \\end{bmatrix}\n",
    "+ b \\begin{bmatrix}\n",
    "      1 \\\\\n",
    "      2\n",
    "   \\end{bmatrix}\n",
    "   = \\begin{bmatrix}\n",
    "       -2b \\\\\n",
    "       +2b\n",
    "     \\end{bmatrix}\n",
    "   = 2 \\begin{bmatrix}\n",
    "        -b \\\\\n",
    "        b\n",
    "      \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "which has eigenvalue 2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b500f1bb",
   "metadata": {},
   "source": [
    "\n",
    "We can obtain an intuition into how to find eigenvectors by \n",
    "rearranging the equation.\n",
    "\n",
    "$$\n",
    "  A\\mathbf{v} = \\lambda \\mathbf{v} = \\lambda I \\mathbf{v}\n",
    "$$\n",
    "\n",
    "$$\n",
    "  (A - \\lambda I) \\mathbf{v} = \\mathbf{0}\n",
    "$$\n",
    "\n",
    "Let $M = (A - \\lambda I)$ then we can rewrite the above as\n",
    "\n",
    "$$\n",
    "  M \\mathbf{v} = \\mathbf{0}\n",
    "$$\n",
    "\n",
    "Thus the eigenvectors for a given $\\lambda$ span the nullspace of \n",
    "$M$ and $\\det(M) = 0$.  Thus,\n",
    "\n",
    "$$\n",
    "  \\det(A - \\lambda I) = 0. \\tag{1}\n",
    "$$\n",
    "\n",
    "The video uses an example matrix $A$\n",
    "\n",
    "$$\n",
    "  A = \\begin{bmatrix}\n",
    "    2 & 2 \\\\\n",
    "    1 & 3 \n",
    "    \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Thus we rewrite (1) as   \n",
    "\n",
    "$$\n",
    "  \\det \\left(\\begin{bmatrix}\n",
    "    2-\\lambda & 2 \\\\\n",
    "    1         & 3-\\lambda \n",
    "  \\end{bmatrix} \\right) = 0. \\tag{3}\n",
    "$$\n",
    "\n",
    "Taking the determinant of (3) yields\n",
    "\n",
    "$$\n",
    "  (2-\\lambda)(3-\\lambda) - 2 \\cdot 1 = 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "  6 - 5 \\lambda + \\lambda^2 - 2 = 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "  (\\lambda-4)(\\lambda-1) = 0\n",
    "$$\n",
    "\n",
    "This has two eigenvalues: $\\lambda = 4$ or $\\lambda = 1$.\n",
    "\n",
    "Now let's find the eigenvectors each eigenvalue.  For the eigenvalue 1,\n",
    "\n",
    "$$\n",
    "  \\begin{bmatrix}\n",
    "    1 & 2 \\\\\n",
    "    1 & 2 \n",
    "  \\end{bmatrix} \\mathbf{v} = 0. \\tag{2}\n",
    "$$\n",
    "\n",
    "Given that this matrix is underspecified, the solution is not a single vector\n",
    "but a line: x+2y = 0.  Any multiple of $(1, -\\tfrac{1}{2})$ satisfies this.\n",
    "\n",
    "We can confirm this\n",
    "\n",
    "$$\n",
    "    \\begin{bmatrix}\n",
    "    2 & 2 \\\\\n",
    "    1 & 3 \n",
    "    \\end{bmatrix} \n",
    "    \\begin{bmatrix}\n",
    "    1 \\\\\n",
    "    -\\tfrac{1}{2}\n",
    "    \\end{bmatrix} = \n",
    "    \\begin{bmatrix}\n",
    "    2 \\\\\n",
    "    1\n",
    "    \\end{bmatrix}\n",
    "    - \\tfrac{1}{2}\\begin{bmatrix}\n",
    "    2 \\\\\n",
    "    3\n",
    "    \\end{bmatrix} =\n",
    "    1 \\cdot\n",
    "    \\begin{bmatrix}\n",
    "    1 \\\\\n",
    "    -\\tfrac{1}{2}\n",
    "    \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "For the eigenvalue 4,\n",
    "\n",
    "$$\n",
    "  \\begin{bmatrix}\n",
    "    2-4 & 2 \\\\\n",
    "    1   & 3-4\n",
    "  \\end{bmatrix} \\mathbf{v} = 0. \n",
    "$$\n",
    "\n",
    "$$\n",
    "  \\begin{bmatrix}\n",
    "    -2 & 2 \\\\\n",
    "    1  & -1\n",
    "  \\end{bmatrix} \\mathbf{v} = 0. \n",
    "$$\n",
    "\n",
    "$$-2 x + 2 y = 0$$\n",
    "\n",
    "So any multiple of $(1,1)$ satisfies this equation.\n",
    "\n",
    "So we have two eigenvectors $(1,1)$ and $(1, -\\tfrac{1}{2})$\n",
    "\n",
    "The video then goes on to discuss how some transformations\n",
    "have no eigenvectors.  For example, in 2-d a rotation moves all\n",
    "vectors and if we try to compute the eigenvalues we get only\n",
    "imaginary roots when solving $\\det(A-I\\lambda) = 0$.\n",
    "\n",
    "It also shows how if your basis vectors are eigenvectors then \n",
    "the eigenvalues are the numbers along the diagonal and all\n",
    "off-diagonal numbers are zero.  When only the diagonal entries\n",
    "are non-zero, we have a *diagonal matrix*.\n",
    "\n",
    "If we mulitply a diagonal to itself we end up with matrix\n",
    "that has the same diagonal values but squared.   If multiply\n",
    "a matrix by itself $k$ times then the diagonals are just\n",
    "the original values to the $k$th power.  For example,\n",
    "\n",
    "$$\n",
    "   A A A A = \\begin{bmatrix}\n",
    "                 2 & 0 \\\\\n",
    "                 0 & 3\n",
    "              \\end{bmatrix}\n",
    "              \\begin{bmatrix}\n",
    "                 2 & 0 \\\\\n",
    "                 0 & 3\n",
    "              \\end{bmatrix}\n",
    "              \\begin{bmatrix}\n",
    "                 2 & 0 \\\\\n",
    "                 0 & 3\n",
    "              \\end{bmatrix}\n",
    "              \\begin{bmatrix}\n",
    "                 2 & 0 \\\\\n",
    "                 0 & 3\n",
    "              \\end{bmatrix}\n",
    "              = \n",
    "              \\begin{bmatrix}\n",
    "                 2^4 & 0 \\\\\n",
    "                 0 & 3^4\n",
    "              \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "When the basis vectors are eigenvectors, we call this an eigenbasis.  If we can \n",
    "find an eigenbasis that spans the space of the original matrix, we can\n",
    "perform a change of basis to the eigenbasis and then operations like\n",
    "multiplying a matrix by itself become inexpensive. \n",
    "\n",
    "In fact any matrix operation that can be expressed as a power series\n",
    "becomes cheap.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6bd60a",
   "metadata": {},
   "source": [
    "**Grading note:** Any answer that discusses the definition\n",
    "of eigenvectors and eigen values and how to compute them is \n",
    "satisfactory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72636980",
   "metadata": {},
   "source": [
    "## Part B. Basic Properties of Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab6c706",
   "metadata": {},
   "source": [
    "1. **Transpose Properties**  \n",
    "Let  \n",
    "\n",
    "$$\n",
    "A = \\begin{bmatrix} 1 & 2 \\\\ 3 & 4 \\end{bmatrix}, \\quad \n",
    "B = \\begin{bmatrix} 0 & -1 \\\\ 1 & 0 \\end{bmatrix}.\n",
    "$$  \n",
    "\n",
    "Verify each of the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb25863",
   "metadata": {},
   "source": [
    "a) $(A+B)^T = A^T + B^T$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee1b1d3",
   "metadata": {},
   "source": [
    "*A:* \n",
    "\n",
    "$$\n",
    "\\left(\\begin{bmatrix} 1 & 2 \\\\ 3 & 4 \\end{bmatrix} \\, +\n",
    "\\begin{bmatrix} 0 & -1 \\\\ 1 & 0 \\end{bmatrix}\\right)^T = \n",
    "\\begin{bmatrix} 1 & 1 \\\\ 4 & 4 \\end{bmatrix}^T =\n",
    "\\begin{bmatrix} 1 & 4 \\\\ 1 & 4 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} 1 & 2 \\\\ 3 & 4 \\end{bmatrix}^T \\, +\n",
    "\\begin{bmatrix} 0 & -1 \\\\ 1 & 0 \\end{bmatrix}^T =\n",
    "\\begin{bmatrix} 1 & 3 \\\\ 2 & 4 \\end{bmatrix} \\, +\n",
    "\\begin{bmatrix} 0 & 1 \\\\ -1 & 0 \\end{bmatrix} =\n",
    "\\begin{bmatrix} 1 & 4 \\\\ 1 & 4 \\end{bmatrix}\n",
    "\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e226b26",
   "metadata": {},
   "source": [
    "b) $ (AB)^T = B^T A^T $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4761d84b",
   "metadata": {},
   "source": [
    "$$\n",
    "\\left(\\begin{bmatrix} 1 & 2 \\\\ 3 & 4 \\end{bmatrix} \n",
    "\\begin{bmatrix} 0 & -1 \\\\ 1 & 0 \\end{bmatrix}\\right)^T =\n",
    "\\begin{bmatrix} 2 & -1 \\\\ 4 & -3 \\end{bmatrix}^T = \n",
    "\\begin{bmatrix} 2 & 4 \\\\ -1 & -3 \\end{bmatrix}\n",
    "$$  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e445185",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{bmatrix} 0 & -1 \\\\\n",
    "                1 & 0 \\end{bmatrix}^T\n",
    "\\begin{bmatrix} 1 & 2 \\\\\n",
    "                3 & 4 \\end{bmatrix}^T =\n",
    "\\begin{bmatrix} 0 & 1 \\\\\n",
    "                -1 & 0 \\end{bmatrix}\n",
    "\\begin{bmatrix} 1 & 3 \\\\\n",
    "                2 & 4 \\end{bmatrix} =\n",
    "\\begin{bmatrix} 2 & 4 \\\\ -1 & -3 \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5d503a",
   "metadata": {},
   "source": [
    "c) $ (A^T)^T = A $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca89f27b",
   "metadata": {},
   "source": [
    "$$\n",
    "\\left(\\begin{bmatrix} 1 & 2 \\\\\n",
    "                      3 & 4 \\end{bmatrix}^T\\right)^T =\n",
    "      \\begin{bmatrix} 1 & 3 \\\\\n",
    "                      2 & 4 \\end{bmatrix}^T =                      \n",
    "      \\begin{bmatrix} 1 & 2 \\\\\n",
    "                      3 & 4 \\end{bmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82c13ad",
   "metadata": {},
   "source": [
    "2. **Trace Identities**  \n",
    "For the same $A, B$, compute $\\mathrm{tr}(A)$, $\\mathrm{tr}(B)$, $\\mathrm{tr}(AB)$, and $\\mathrm{tr}(BA)$.  \n",
    "Show that $\\mathrm{tr}(AB) = \\mathrm{tr}(BA)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047cd82b",
   "metadata": {},
   "source": [
    "$$\n",
    "A = \\begin{bmatrix}\n",
    "  1 & 2 \\\\\n",
    "  3 & 4 \n",
    "\\end{bmatrix}\\quad \n",
    "B = \\begin{bmatrix}\n",
    "  0 & -1 \\\\\n",
    "  1 & 0 \n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\operatorname{tr}(A) = \\sum_{i=1}^n a_{ii}\n",
    "  = \\operatorname{tr}\\left(\n",
    "  \\begin{bmatrix}\n",
    "    1 & 2 \\\\\n",
    "   3 & 4 \n",
    "  \\end{bmatrix}\n",
    "  \\right) = 1 + 4 = 5\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\operatorname{tr}(B) = \\sum_{i=1}^n b_{ii}\n",
    "  = \\operatorname{tr}\\left(\n",
    "  \\begin{bmatrix}\n",
    "    0 & -1 \\\\\n",
    "    1 & 0 \n",
    "  \\end{bmatrix}\n",
    "  \\right) = 0 + 0 = 0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1d97b7",
   "metadata": {},
   "source": [
    "$$\n",
    "\\operatorname{tr}(AB) = \n",
    "  = \\operatorname{tr}\\left(\n",
    "    \\begin{bmatrix}\n",
    "    1 & 2 \\\\\n",
    "    3 & 4 \n",
    "  \\end{bmatrix}\n",
    "  \\begin{bmatrix}\n",
    "    0 & -1 \\\\\n",
    "    1 & 0 \n",
    "  \\end{bmatrix}\n",
    "  \\right) \n",
    "  = \\operatorname{tr}\\left(\n",
    "    \\begin{bmatrix}\n",
    "    2 & -1 \\\\\n",
    "    4 & -3 \n",
    "  \\end{bmatrix}\n",
    "  \\right) \n",
    "= 2-3 = -1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49f2255",
   "metadata": {},
   "source": [
    "$$\n",
    "\\operatorname{tr}(BA) = \n",
    "  = \\operatorname{tr}\\left(\n",
    "  \\begin{bmatrix}\n",
    "    0 & -1 \\\\\n",
    "    1 & 0 \n",
    "  \\end{bmatrix}\n",
    "  \\begin{bmatrix}\n",
    "    1 & 2 \\\\\n",
    "    3 & 4 \n",
    "  \\end{bmatrix}\n",
    "  \\right) \n",
    "  = \\operatorname{tr}\\left(\n",
    "    \\begin{bmatrix}\n",
    "    2 & -1 \\\\\n",
    "    4 & -3 \n",
    "  \\end{bmatrix}\n",
    "  \\right) \n",
    "= 2-3 = -1\n",
    "$$\n",
    "\n",
    "The above two answers show that $\\operatorname{tr}(AB) = \n",
    "\\operatorname{tr}(BA)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02469ce6",
   "metadata": {},
   "source": [
    "3. **Inner Product**  \n",
    "Let $\\mathbf{x} = [1,2,3]^T$, $\\mathbf{y} = [4,0,-1]^T$.  \n",
    "a) Compute $\\mathbf{x}^T \\mathbf{y}$.  \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ec053d",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "$$\n",
    "\\mathbf{x} =\n",
    "\\begin{bmatrix}\n",
    "  1 \\\\\n",
    "  2 \\\\\n",
    "  3 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    " \n",
    "Thus,\n",
    "\n",
    "$$\n",
    "\\mathbf{x}^T \\mathbf{y} =\n",
    "\\begin{bmatrix}\n",
    "1 & 2 & 3 \n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "4 \\\\\n",
    "0 \\\\\n",
    "-1\n",
    "\\end{bmatrix} =\n",
    "1 \\cdot 4 + 2 \\cdot 0 + 3 \\cdot (-1) = 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e04fc23",
   "metadata": {},
   "source": [
    "b) Interpret the inner product in terms of vector similarity.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f2476c",
   "metadata": {},
   "source": [
    "When two vectors point in the same direction, the inner product is the length of each vector multiplied together.   When the vectors are at right angles, the inner product is zero.  One can think of it as a measure of how much the vectors point in the same direction scaled by the size of each vector.   More formally\n",
    "\n",
    "$$ \\mathbf{x} \\cdot \\mathbf{y} = \\|\\mathbf{x}\\| \\|\\mathbf{y}\\| \\cos \\theta\n",
    "$$\n",
    "\n",
    "where $\\theta$ is the angle between $\\mathbf{x}$ and $\\mathbf{y}.$\n",
    "\n",
    "Sometimes when someone refers to similarity between vectors they \n",
    "are using a descriptive phrase that could mean anything like cosine\n",
    "similarity which is the measure of the angle between \n",
    "$\\mathbf{x}$ and $\\mathbf{y}$.\n",
    "\n",
    "$$\\cos \\theta = \\frac{\\mathbf{x} \\cdot \\mathbf{y}}{\\|\\mathbf{x}\\| \\|\\mathbf{y}\\|}$$\n",
    "\n",
    "In this case, \n",
    "\n",
    "$$\\theta = \\cos^{-1} \\left( \\tfrac{1}{\\| x \\| \\| y \\|} \\right) \n",
    "         = \\cos^{-1} \\left( \\tfrac{1}{\\sqrt{14} \\sqrt{17}} \\right)$$ \n",
    "\n",
    "$$\\theta \\approx 86.3$$\n",
    "\n",
    "Grading note:  Any answer that relates the dot product to cosine\n",
    "of the angle between the vectors is adequate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798b7611",
   "metadata": {},
   "source": [
    "\n",
    "4. **Outer Product**  \n",
    "Using the same vectors $\\mathbf{x}, \\mathbf{y}$:  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be9fcd6",
   "metadata": {},
   "source": [
    "a) Compute $\\mathbf{x}\\mathbf{y}^T$.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d120cc",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "$$\n",
    "\\mathbf{x} \\mathbf{y}^T =\n",
    "\\begin{bmatrix}\n",
    "  1 \\\\ 2 \\\\ 3 \n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "4 & 0 & -1\n",
    "\\end{bmatrix} =\n",
    "\\begin{bmatrix}\n",
    "4  & 0 & -1 \\\\\n",
    "8  & 0 & -2 \\\\\n",
    "12 & 0 & -3\n",
    "\\end{bmatrix} \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9727f525",
   "metadata": {},
   "source": [
    "\n",
    "b) What is the shape of the resulting matrix?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21969d58",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "Unlike a dot product, which results in a scalar, an inner product produces a $n \\times n$\n",
    "matrix where $n$ is the dimensionality of the vectors.  In the case of $\\mathbf{x} \\mathbf{y}^T$,\n",
    "the resulting matrix is $3 \\times 3$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd941db",
   "metadata": {},
   "source": [
    "5. **Hadamard Product**  \n",
    "    Let  \n",
    "    $$\n",
    "    U = \\begin{bmatrix} 1 & 2 \\\\ 3 & 4 \\end{bmatrix}, \\quad \n",
    "    V = \\begin{bmatrix} 5 & 6 \\\\ 7 & 8 \\end{bmatrix}.\n",
    "    $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35b6fe9",
   "metadata": {},
   "source": [
    "\n",
    "a) Compute the Hadamard product $U \\odot V$.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee3d87e",
   "metadata": {},
   "source": [
    "\n",
    "**Answer:**\n",
    "\n",
    "$$\n",
    "U \\odot V =\n",
    "  \\begin{bmatrix}\n",
    "    1 & 2 \\\\\n",
    "    3 & 4 \n",
    "  \\end{bmatrix}\n",
    "  \\odot\n",
    "  \\begin{bmatrix}\n",
    "    5 & 6 \\\\\n",
    "    7 & 8\n",
    "    \\end{bmatrix}\n",
    "  =\n",
    "  \\begin{bmatrix}\n",
    "    1 \\cdot 5 & 2 \\cdot 6 \\\\\n",
    "    3 \\cdot 7 & 4 \\cdot 8\n",
    "  \\end{bmatrix}\n",
    "  =\n",
    "  \\begin{bmatrix}\n",
    "    5 & 12 \\\\\n",
    "    21 & 32\n",
    "  \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90a9c82",
   "metadata": {},
   "source": [
    "\n",
    "b) Compare this elementwise product to the matrix product $UV$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b87217e0",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "$$\n",
    "U V =\n",
    "  \\begin{bmatrix}\n",
    "    1 & 2 \\\\\n",
    "    3 & 4 \n",
    "  \\end{bmatrix}\n",
    "  \\begin{bmatrix}\n",
    "    5 & 6 \\\\\n",
    "    7 & 8\n",
    "  \\end{bmatrix}\n",
    "  =\n",
    "  \\begin{bmatrix}\n",
    "    19 & 22 \\\\\n",
    "    43 & 50\n",
    "  \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40b63e4",
   "metadata": {},
   "source": [
    "c) Where does the Hadamard product appear in machine learning (give one example)?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd7a958",
   "metadata": {},
   "source": [
    "**Answer**:  *IGNORE*\n",
    "\n",
    "This is an unfair question given that we haven't used it yet.\n",
    "\n",
    "It does appear in backpropagation.\n",
    "\n",
    "**Grading note**: ignore this problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10055def",
   "metadata": {},
   "source": [
    "6. **Determinant and Inverse**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ef6b83",
   "metadata": {},
   "source": [
    "a) Compute $\\det(A)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b6c3f1",
   "metadata": {},
   "source": [
    "**Answer**\n",
    "\n",
    "$$\n",
    "\\det(A) = \n",
    "  \\begin{vmatrix}\n",
    "    1 & 2 \\\\ \n",
    "    3 & 4\n",
    "  \\end{vmatrix} =\n",
    "  4 - 6 = -2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4beaa75b",
   "metadata": {},
   "source": [
    "b) Determine if $A$ is invertible, and if so, find $A^{-1}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66c39d6",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "Any matrix with a non-zero determinant is invertible. Thus $A$ is invertible.\n",
    "\n",
    "The inverse matrix $A^{-1}$ satisfies $A A^{-1} = I.$\n",
    "\n",
    "For a $2 \\times 2$ matrix there is a well known solution\n",
    "\n",
    "$$\n",
    "A^{-1} = \\frac{1}{\\det(A)} \n",
    "  \\begin{bmatrix}\n",
    "    d  & -b \\\\\n",
    "    -c & a\n",
    "  \\end{bmatrix}\n",
    "$$ \n",
    "\n",
    "Substituting the determinant from part (a) and the values for the matrix,\n",
    "\n",
    "$$\n",
    "A^{-1} = -\\tfrac12\n",
    "  \\begin{bmatrix}\n",
    "    4  & -2 \\\\\n",
    "    -3 & 1\n",
    "  \\end{bmatrix}\n",
    "  = \\begin{bmatrix}\n",
    "    -2  & 1 \\\\\n",
    "    \\tfrac{3}{2} & -\\tfrac{1}{2}\n",
    "  \\end{bmatrix}\n",
    "$$ \n",
    "\n",
    "We can confirm the inverse is correct by multiplying $A$ with $A^{-1}$ as follows\n",
    "\n",
    "$$\n",
    "A A^{-1} = \n",
    "  \\begin{vmatrix}\n",
    "    1 & 2 \\\\ \n",
    "    3 & 4\n",
    "  \\end{vmatrix} \n",
    "  \\begin{bmatrix}\n",
    "    -2  & 1 \\\\\n",
    "    \\tfrac{3}{2} & -\\tfrac{1}{2}\n",
    "  \\end{bmatrix}\n",
    "  =\n",
    "  \\begin{bmatrix}\n",
    "    1 \\cdot (-2) + 2 \\cdot \\tfrac{3}{2} & 1 \\cdot 1 + 2 \\cdot (-\\tfrac{1}{2}) \\\\\n",
    "    3 \\cdot (-2) + 4 \\cdot \\tfrac{3}{2} & 3 \\cdot 1 + 4 \\cdot (-\\tfrac{1}{2}) \n",
    "  \\end{bmatrix}\n",
    "  = \\begin{bmatrix}\n",
    "    1 & 0 \\\\\n",
    "    0 & 1\n",
    "  \\end{bmatrix}\n",
    "  $$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9a62de6",
   "metadata": {},
   "source": [
    "c) Verify that $\\det(A^{-1}) = 1/\\det(A)$.\n",
    "\n",
    "**Answer:**\n",
    "\n",
    "From (a) we know $\\det(A) = -2$.\n",
    "\n",
    "$$\\det(A^{-1}) = -2 \\cdot (-\\tfrac12 ) - 1 \\cdot \\tfrac{3}{2} = - \\tfrac{1}{2}$$\n",
    "\n",
    "$- \\tfrac{1}{2}$ is the reciprocal of $-2$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8255842",
   "metadata": {},
   "source": [
    "## Part C. Linear Dependence and Span"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27f8bff",
   "metadata": {},
   "source": [
    "7. Consider the vectors  \n",
    "$\\mathbf{v}_1 = [1,2,3]^T, \\\\ \\mathbf{v}_2 = [2,4,6]^T, \\\\ \\mathbf{v}_3 = [1,0,1]^T.$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7385062e",
   "metadata": {},
   "source": [
    "a) Determine whether $\\{\\mathbf{v}_1, \\mathbf{v}_2, \\mathbf{v}_3\\}$ are linearly independent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be74e460",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "For the vectors do be linearly independent, none can be expressed as a linear\n",
    "combination of the others.   In this problem,  $\\mathbf{v}_2 = 2 \\mathbf{v}_1$.\n",
    "\n",
    "Not linearly independent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e6972f",
   "metadata": {},
   "source": [
    "b) Find a maximal independent subset of these vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e2e96b",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "$\\mathbf{v}_1$ and $\\mathbf{v}_3$ are not collinear, and\n",
    "$\\mathbf{v}_2$ and $\\mathbf{v}_3$ are not collinear, so \n",
    "either $\\{\\mathbf{v}_1, \\mathbf{v}_3\\}$ or $\\{\\mathbf{v}_2, \\mathbf{v}_3\\}$ are\n",
    "maximal independent subsets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2d7d45",
   "metadata": {},
   "source": [
    "c) Describe the span of this set in $\\mathbb{R}^3$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa2d7eb",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "Even though the vectors are 3-dimension, they are not independent, so they do no\n",
    "spen $\\mathbb{R}^3$.  However, the two independent subsets describe the same plane.\n",
    "The vectors span\n",
    "\n",
    "$$\\forall a, b \\in \\mathbb{R}: a\\mathbf{v}_1 + b\\mathbf{v}_3$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7017eebe",
   "metadata": {},
   "source": [
    "8. Let  \n",
    "$$\n",
    "M = \\begin{bmatrix} \n",
    "1 & 2 & 3 \\\\ \n",
    "2 & 4 & 6 \\\\ \n",
    "1 & 0 & 1 \n",
    "\\end{bmatrix}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5a66fc",
   "metadata": {},
   "source": [
    "a) Find $\\mathrm{rank}(M)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1fe02c",
   "metadata": {},
   "source": [
    "**Answer:** \n",
    "\n",
    "The rank is equal to the maximum number of independent column vectors or row vectors.\n",
    "\n",
    "When considering row vectors\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "  1 \\\\ \n",
    "  2 \\\\\n",
    "  1\n",
    "\\end{bmatrix}\n",
    "+ \\begin{bmatrix}\n",
    "  2 \\\\\n",
    "  4 \\\\\n",
    "  0\n",
    "\\end{bmatrix}\n",
    "= \\begin{bmatrix}\n",
    "  3 \\\\\n",
    "  6 \\\\\n",
    "  1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "We can express any one column vector as a linear combination of the other two.\n",
    "Thus, the rank is 2. \n",
    "\n",
    "We can also see that the second row is twice the first row, but the \n",
    "third row cannot be expressed as a linear combination of the first 2, \n",
    "so the rank as determined by row vectors is also 2.\n",
    "\n",
    "As an aside, the rank is always the same whether determined from row\n",
    "vectors or column vectors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6889bbe",
   "metadata": {},
   "source": [
    "b) Explain how the rank relates to the results from Problem 4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d632f4",
   "metadata": {},
   "source": [
    "put answer here (or on scanned paper)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21261052",
   "metadata": {},
   "source": [
    "## Part D. Norms and Distances"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83b11a0",
   "metadata": {},
   "source": [
    "9. Compute the following norms of $\\mathbf{x} = [3, -4]^T$:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4853c876",
   "metadata": {},
   "source": [
    "a) $|\\mathbf{x}|_1 $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a309bf4b",
   "metadata": {},
   "source": [
    "**Answer:** \n",
    "\n",
    "Often referred to as the $L^1$ (pronounced \"ell-one\") norm, it\n",
    "refers to the sum of the absolute value of the vector's components.\n",
    "\n",
    "$$\\|\\mathbf{x}\\|_1 = \\sum_{i=1}^n |x_i|.$$\n",
    "\n",
    "So, for $\\mathbf{x} = [3, -4]^T$,\n",
    "\n",
    "$$\\|\\mathbf{x}\\|_1 = |3| + |-4| = 7$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe38ad2f",
   "metadata": {},
   "source": [
    "b) $ |\\mathbf{x}|_2 $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb184220",
   "metadata": {},
   "source": [
    "**Answer:** \n",
    "\n",
    "Often referred to as the $L^2$ (pronounced \"ell-two\") norm, it\n",
    "refers to the square root of the sum of the squares of the \n",
    "vector's components.  This is the same as the *Euclidean norm*.\n",
    "\n",
    "$$\\|\\mathbf{x}\\|_2 = \\sqrt{\\sum_{i=1}^n x_i^2}.$$\n",
    "\n",
    "So, for $\\mathbf{x} = [3, -4]^T$,\n",
    "\n",
    "$$\\|\\mathbf{x}\\|_2 = \\sqrt{3^2 + (-4)^2} = 5$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb786f2e",
   "metadata": {},
   "source": [
    "c) $ |\\mathbf{x}|_\\infty $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab7b649",
   "metadata": {},
   "source": [
    "**Answer:** The definition of norms generalizes to $\\infty$ as follows\n",
    "\n",
    "$$\\|x\\|_\\infty = \\left( \\sum_{i=1}^n |x_i|^\\infty \\right)^{1/\\infty}$$\n",
    "\n",
    "What this means may not be obvious.  Consider as we increase the exponent\n",
    "on the absolute value, the largest value races ahead of any smaller value.\n",
    "Thus, to compute this norm, the norm is the component with the maximum\n",
    "absolute value among all of the components in the vector.\n",
    "\n",
    "$$\\|x\\|_\\infty = \\max_i|x_i|$$\n",
    "\n",
    "For $\\mathbf{x} = [3, -4]^T$,\n",
    "\n",
    "$$\\|x\\|_\\infty = 4$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e70e90d",
   "metadata": {},
   "source": [
    "10. Prove or verify numerically that for any vector \n",
    "$\\mathbf{x} \\in \\mathbb{R}^n$,\n",
    "\n",
    "$$\n",
    "   \\|\\mathbf{x}\\|_\\infty \\le \\|\\mathbf{x}\\|_2 \\le \\|\\mathbf{x}\\|_1.\n",
    "$$  \n",
    "\n",
    "Use $\\mathbf{x} = [3,-4]^T$ as an example.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f581fa92",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "Numerically is easy.\n",
    "\n",
    "$$\\|\\mathbf{x}\\|_\\infty = 4$$\n",
    "\n",
    "$$\\|\\mathbf{x}\\|_2 = \\sqrt{3^2 + (-4)^2} = 5$$\n",
    "\n",
    "$$\\|\\mathbf{x}\\|_1 = |3| + |-4| = 7$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4db4cc9",
   "metadata": {},
   "source": [
    "Proving this is a little more involved for arbitrary $n$.\n",
    "\n",
    "$$(x_1​+x_2​+ \\cdots +x_n​)^2= \\sum_{i=1}^n x_i^2 + 2 \\sum_{1 \\le i < j \\le n} x_i x_j$$\n",
    "\n",
    "Similarly,\n",
    "\n",
    "$$(|x_1|​+|x_2|​+ \\cdots + |x_n| ​)^2= \\sum_{i=1}^n |x_i|^2 + 2 \\sum_{1 \\le i < j \\le n} |x_i| |x_j|$$\n",
    "\n",
    "Taking the square root of both sides yields\n",
    "\n",
    "$$\\sqrt{(|x_1|​+|x_2|​+ \\cdots + |x_n| ​)^2} = \\sqrt{\\sum_{i=1}^n |x_i|^2 + 2 \\sum_{1 \\le i < j \\le n} |x_i| |x_j|}$$\n",
    "\n",
    "which simplifies to\n",
    "\n",
    "$$|x_1|​+|x_2|​+ \\cdots + |x_n| = \\sqrt{\\sum_{i=1}^n |x_i|^2 + 2 \\sum_{1 \\le i < j \\le n} |x_i| |x_j|}.  \\tag{9.1}$$\n",
    "\n",
    "Because $|x_i| |x_j|$ is guaranteed to be nonnegative,\n",
    "\n",
    "$$2 \\sum_{1 \\le i < j \\le n} |x_i| |x_j| \\ge 0$$\n",
    "\n",
    "So from (9.1),\n",
    "\n",
    "$$\\sqrt{\\sum_{i=1}^n |x_i|^2 + 2 \\sum_{1 \\le i < j \\le n} |x_i| |x_j|} \\ge \\sqrt{\\sum_{i=1}^n |x_i|^2}$$\n",
    "\n",
    "Thus,\n",
    "\n",
    "$$|x_1|​+|x_2|​+ \\cdots + |x_n| \\ge \\sqrt{\\sum_{i=1}^n |x_i|^2}.$$\n",
    "\n",
    "So,\n",
    "\n",
    "$$\\|\\mathbf{x}\\|_1 \\ge \\|\\mathbf{x}\\|_2. \\tag{9.2}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a061a59d",
   "metadata": {},
   "source": [
    "\n",
    "To show $\\|\\mathbf{x}\\|_\\infty \\le \\|\\mathbf{x}\\|_2$, let $j = \\argmax_i |x_i|$.  Then,\n",
    "\n",
    "$$\\sqrt{x_j^2} = |x_j| = \\max |x_i| = \\|\\mathbf{x}\\|_\\infty. \\tag{9.3}$$\n",
    "\n",
    "Because $\\forall i: x_i^2 \\ge 0$,\n",
    "\n",
    "$$\\sum_i x_i^2 = x_1^2 + \\cdots + x_j^2 + \\cdots x_n^2 \\ge x_j^2$$\n",
    "\n",
    "Because square root is an increasing function, taking the square root of both sides does not change the direction of the inequality.\n",
    "\n",
    "$$\\sqrt{\\sum_i x_i^2} \\ge \\sqrt{x_j^2}. \\tag{9.4}$$\n",
    "\n",
    "Substituting $(9.3)$ into $(9.4)$ yields\n",
    "\n",
    "$$\\sqrt{\\sum_i x_i^2} \\ge \\|\\mathbf{x}\\|_\\infty.$$\n",
    "\n",
    "The lefthand side is the definition of $\\|\\mathbf{x}\\|_2$ so\n",
    "\n",
    "$$\\|\\mathbf{x}\\|_2 \\ge \\|\\mathbf{x}\\|_\\infty. \\tag{9.5}$$\n",
    "\n",
    "Combining $(9.2)$ and $(9.5)$ yields\n",
    "\n",
    "$$ \\|\\mathbf{x}\\|_\\infty \\le \\|\\mathbf{x}\\|_2 \\le \\|\\mathbf{x}\\|_1.$$\n",
    "\n",
    "QED"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d2351c",
   "metadata": {},
   "source": [
    "11. For vectors $\\mathbf{u} = [1,1]^T$ and $\\mathbf{v} = [2,0]^T$, compute:  \n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cf659c",
   "metadata": {},
   "source": [
    "a) Euclidean distance $\\|\\mathbf{u} - \\mathbf{v}\\|_2$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bbdeea",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "$$\\|\\mathbf{u} - \\mathbf{v}\\|_2 = \\|[-1,1]^T\\|_2 = \\sqrt{(-1)^2 + 1^2} = \\sqrt{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf997a88",
   "metadata": {},
   "source": [
    "b) Cosine similarity $\\frac{\\mathbf{u}^T \\mathbf{v}}{\\|\\mathbf{u}\\|_2 \\|\\mathbf{v}\\|_2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784356eb",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "$$\\cos \\theta = \\frac{1 \\cdot 2 + 1 \\cdot 0}{\\sqrt{2} \\cdot 2}$$\n",
    "\n",
    "Simplifying yields\n",
    "\n",
    "$$\\frac{1}{\\sqrt{2}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3026369",
   "metadata": {},
   "source": [
    "## Part D. Trace Properties\n",
    "\n",
    "12. **Linearity of Trace**\n",
    "Let\n",
    "$$\n",
    "C = \\begin{bmatrix} 1 & 2 \\\\ 0 & 1 \\end{bmatrix}, \\quad \n",
    "D = \\begin{bmatrix} 2 & 0 \\\\ 3 & 1 \\end{bmatrix}.\n",
    "$$\n",
    "a) $\\mathrm{tr}(C+D) = \\mathrm{tr}(C) + \\mathrm{tr}(D)$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3380c179",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "$$\n",
    "\\operatorname{tr}\\left(\n",
    "\\begin{bmatrix}\n",
    "  1 & 2 \\\\\n",
    "  0 & 1\n",
    "\\end{bmatrix}\n",
    "+ \\begin{bmatrix}\n",
    "  2 & 0 \\\\\n",
    "  3 & 1\n",
    "\\end{bmatrix}\n",
    "\\right)\n",
    "=\n",
    "\\operatorname{tr}\\left(\n",
    "\\begin{bmatrix}\n",
    "  3 & 2 \\\\\n",
    "  3 & 2\n",
    "\\end{bmatrix}\n",
    "\\right) = 5\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\operatorname{tr}\\left(\n",
    "\\begin{bmatrix}\n",
    "  1 & 2 \\\\\n",
    "  0 & 1\n",
    "\\end{bmatrix}\n",
    "\\right) = 2\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\operatorname{tr}\\left(\n",
    "\\begin{bmatrix}\n",
    "  2 & 0 \\\\\n",
    "  3 & 1\n",
    "\\end{bmatrix}\n",
    "\\right) = 3\n",
    "$$\n",
    "\n",
    "$$\\operatorname{tr}(C) + \\operatorname{tr}(D) = 5$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b6bd56",
   "metadata": {},
   "source": [
    "b) $\\mathrm{tr}(\\alpha C) = \\alpha \\,\\mathrm{tr}(C)$ for scalar $\\alpha = 3$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2e8dae",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "$$\\operatorname{tr}\\left(3\\cdot\n",
    "\\begin{bmatrix}\n",
    "  1 & 2 \\\\\n",
    "  0 & 1\n",
    "\\end{bmatrix}\n",
    "\\right) = \\operatorname{tr}\\left(\n",
    "\\begin{bmatrix}\n",
    "  3 & 6 \\\\\n",
    "  0 & 3\n",
    "\\end{bmatrix}\n",
    "\\right) = 6\n",
    "$$\n",
    "\n",
    "$$3 \\cdot \\operatorname{tr}\\left(\n",
    "\\begin{bmatrix}\n",
    "  1 & 2 \\\\\n",
    "  0 & 1\n",
    "\\end{bmatrix}\n",
    "\\right) = 3 \\cdot 2 = 6\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bd64d5",
   "metadata": {},
   "source": [
    "13. **Cyclic Property of Trace**\n",
    "Show that for compatible matrices $X, Y$:\n",
    "$\\mathrm{tr}(XY) = \\mathrm{tr}(YX)$.\n",
    "Verify with explicit computation using\n",
    "$$\n",
    "X = \\begin{bmatrix} 1 & 2 \\\\ 0 & 1 \\end{bmatrix}, \\quad \n",
    "Y = \\begin{bmatrix} 0 & 1 \\\\ 1 & 0 \\end{bmatrix}.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91303864",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "Let $X$ and $Y$ be $n \\times n$ matrices.\n",
    "\n",
    "Let $C= XY$\n",
    "\n",
    "$$C_{ij} = \\sum_{k=1}^n X_{ik} Y_{kj} \\tag{13.1}$$\n",
    "\n",
    "$$\\operatorname{tr}(XY) = \\operatorname{tr}(C) = \\sum_{i=1}^n C_{ii} \\tag{13.2}$$\n",
    "\n",
    "Substituting $(13.1)$ into $(13.2)$ yields\n",
    "\n",
    "$$\\operatorname{tr}(XY) = \\sum_{i=1}^n \\sum_{k=1}^n X_{ik} Y_{ki} \\tag{13.3}$$\n",
    "\n",
    "Similarly\n",
    "\n",
    "$$\\operatorname{tr}(YX) = \\sum_{i=1}^n \\sum_{k=1}^n Y_{ik} X_{ki}$$\n",
    "\n",
    "Because additions is commutative,\n",
    "\n",
    "$$\\operatorname{tr}(YX) = \\sum_{k=1}^n \\sum_{i=1}^n Y_{ik} X_{ki}$$\n",
    "\n",
    "Because $i$ and $k$ are bound variables, we can just swap labels to get\n",
    "\n",
    "$$\\operatorname{tr}(YX) = \\sum_{i=1}^n \\sum_{k=1}^n Y_{ki} X_{ik}$$\n",
    "\n",
    "Because scalar multplication is commutative, the above becomes\n",
    "\n",
    "$$\\operatorname{tr}(YX) = \\sum_{i=1}^n \\sum_{k=1}^n X_{ik} Y_{ki} \\tag{13.4}$$\n",
    "\n",
    "Combining $(13.3)$ and $(13.4)$ yields\n",
    "\n",
    "$$\\operatorname{tr}(XY) = \\operatorname{tr}(YX)$$\n",
    "\n",
    "QED.\n",
    "\n",
    "Now we verify with $X$ and $Y$ as defined in the Problem 13 description.\n",
    "\n",
    "$$\n",
    "X = \\begin{bmatrix} 1 & 2 \\\\ 0 & 1 \\end{bmatrix}, \\quad \n",
    "Y = \\begin{bmatrix} 0 & 1 \\\\ 1 & 0 \\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "$$\\operatorname{tr}(XY) \n",
    "  = \\operatorname{tr}\n",
    "      \\begin{bmatrix}\n",
    "       2 & 1 \\\\\n",
    "       1 & 0\n",
    "      \\end{bmatrix} = 2\n",
    "$$\n",
    "\n",
    "$$\\operatorname{tr}(XY) \n",
    "  = \\operatorname{tr}\n",
    "      \\begin{bmatrix}\n",
    "       0 & 1 \\\\\n",
    "       1 & 2\n",
    "      \\end{bmatrix} = 2\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e79faaf",
   "metadata": {},
   "source": [
    "14. **Trace of Outer Product**\n",
    "\n",
    "Let $\\mathbf{a} = [1,2]^T$.\n",
    "Compute $\\mathrm{tr}(\\mathbf{a}\\mathbf{a}^T)$ and explain why this equals $\\|\\mathbf{a}\\|_2^2$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bebb7c2",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "$$\\operatorname{tr}\\left(\n",
    "  \\begin{bmatrix}\n",
    "    1 \\\\\n",
    "    2\n",
    "  \\end{bmatrix}\n",
    "  \\begin{bmatrix}\n",
    "    1 & 2\n",
    "  \\end{bmatrix}\n",
    "\\right) = \n",
    "\\operatorname{tr}\\left(\n",
    "  \\begin{bmatrix}\n",
    "    1 & 2 \\\\\n",
    "    2 & 4\n",
    "  \\end{bmatrix}\n",
    "\\right)\n",
    "= 5\n",
    "$$\n",
    "\n",
    "We can easily explain why this is $\\|\\mathbf{a}\\|_2^2$ \n",
    "by defining $\\mathbf{a} = (x,y)$.\n",
    "\n",
    "$$\\operatorname{tr}\\left(\n",
    "  \\begin{bmatrix}\n",
    "    x \\\\\n",
    "    y\n",
    "  \\end{bmatrix}\n",
    "  \\begin{bmatrix}\n",
    "    x & y\n",
    "  \\end{bmatrix}\n",
    "\\right) = \n",
    "\\operatorname{tr}\\left(\n",
    "  \\begin{bmatrix}\n",
    "    x^2 & xy \\\\\n",
    "    yx  & y^2\n",
    "  \\end{bmatrix}\n",
    "\\right) = x^2 + y^2 = \\|\\mathbf{a}\\|_2^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20aab59",
   "metadata": {},
   "source": [
    "## Part E. Eigenvalues, PSD\n",
    "\n",
    "15. **Eigenvalues and Eigenvectors**\n",
    "\n",
    "Let\n",
    "$$\n",
    "E = \\begin{bmatrix} 2 & 1 \\\\ 1 & 2 \\end{bmatrix}.\n",
    "$$\n",
    "\n",
    "a) Find the eigenvalues and eigenvectors of $E$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac63f1d5",
   "metadata": {},
   "source": [
    "By definition an eigenvector $\\mathbf{v}$ and eigenvalue $\\lambda$ is a solution to\n",
    "\n",
    "$$E\\mathbf{v} = \\lambda\\mathbf{v}$$\n",
    "\n",
    "Which can be rearranged as \n",
    "\n",
    "$$E\\mathbf{v} = \\lambda I \\mathbf{v}$$\n",
    "\n",
    "$$(E- \\lambda I)\\mathbf{v} = 0 \\tag{15.1}$$\n",
    "\n",
    "This can only occur if \n",
    "\n",
    "$$\\det(E - \\lambda I) = 0$$\n",
    "\n",
    "$$\n",
    "\\det\\left(\\begin{bmatrix}\n",
    "  2-\\lambda & 1 \\\\\n",
    "  1         & 2-\\lambda\n",
    "\\end{bmatrix}\\right) = (2-\\lambda)^2 - 1 = (\\lambda - 3)(\\lambda -1) = 0\n",
    "$$\n",
    "\n",
    "This gives us 2 eigenvalues: 1 and 3.\n",
    "\n",
    "We then solve $(15.1)$ for the first eigenvalue, $\\lambda=1$.\n",
    "\n",
    "$$(E - I)\\mathbf{v} = 0 \\tag{15.2}$$\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "  1 & 1 \\\\\n",
    "  1 & 1\n",
    "\\end{bmatrix}\n",
    "\\mathbf{v} = 0\n",
    "$$\n",
    "\n",
    "which is satisfied when $x = -y$.  All multiples of $(1,-1)$ satisfy this.\n",
    "\n",
    "For $\\lambda=3$, \n",
    "\n",
    "$$(E - 3I)\\mathbf{v} = 0$$\n",
    "\n",
    "which expands to\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "  -1 & 1 \\\\\n",
    "  1 & -1\n",
    "\\end{bmatrix}\n",
    "\\mathbf{v} = 0\n",
    "$$\n",
    "\n",
    "This is solved when $\\mathbf{v}$ is a multiple of $(1,1)$, so this matrix\n",
    "has eigenvectors $(1,-1)$ and $(1,1)$ with the eigenvalues \n",
    "$\\lambda = 1$ and $\\lambda=3$ respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3b84a6",
   "metadata": {},
   "source": [
    "b) Verify that $E$ is symmetric and explain why its eigenvalues are guaranteed to be real.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08200ffb",
   "metadata": {},
   "source": [
    "Matrix $E$ is symmetric if and only if it is square and $E = E^T$, i.e., $E_{ij} = E_{ji}$ for all $i, j$.\n",
    "Because $E$ is small, this is easy to show exhaustively.  It is trivially true along the \n",
    "diagonal where $i = j$.  There are only 2 off-diagonal entries:\n",
    "\n",
    "$E_{12} = E_{21} = 1$.\n",
    "\n",
    "$E$ is symmetric.\n",
    "\n",
    "All real symmetric matrices have all real eigenvalues.  have a set of eigenvectors that form an orthonormal basis, meaning\n",
    "the basis vectors are orthogonal and each has length 1.\n",
    "\n",
    "This does not mean that the orthonormal basis vectors represent the \n",
    "entire set of eigenvectors for $E$, because the eigenvectors includes collinear\n",
    "vectors.  For $E$, $(1,1)$ is an eigenvector, but so are all vectors $(a,a)$ \n",
    "for $a \\in \\mathbb{R}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34e91424",
   "metadata": {},
   "source": [
    "16. **Positive Semidefinite Matrices**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b8cb7c",
   "metadata": {},
   "source": [
    "a) Show that $E$ from Problem 15 is positive semidefinite by checking $\\mathbf{x}^T E \\mathbf{x} \\geq 0$ for arbitrary $\\mathbf{x}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dc6233",
   "metadata": {},
   "source": [
    "**Answer:**\n",
    "\n",
    "$E$ is a $2 \\times 2$ matrix thus $\\mathbf{x}$ must be 2-dimensional.\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    " x & y\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "2 & 1 \\\\ 1 & 2\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    " x \\\\ y\n",
    "\\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix}\n",
    "2x + y & x + 2y\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    " x \\\\ y\n",
    "\\end{bmatrix}\n",
    "= \n",
    "(2x + y)x + (x + 2y)y \n",
    "$$\n",
    "\n",
    "To demonstrate that this is greater than or equal to zero for all $x$ and $y$,\n",
    "\n",
    "$$\n",
    "(2x + y)x + (x + 2y)y = 2(x^2 + xy + y^2) = 2(x^2 + xy + \\frac{y^2}{4} + \\frac{3}{4}y^2)\n",
    "  = 2(x + \\frac{y}{4})^2 + 2\\cdot\\frac{3}{4}y^2\n",
    "$$ \n",
    "\n",
    "Because both terms are squared, the result is guaranteed to be greater\n",
    "than or equal to 0.\n",
    "\n",
    "QED.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3a1414",
   "metadata": {},
   "source": [
    "b) Why are PSD matrices important in optimization for machine learning?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f5eeda",
   "metadata": {},
   "source": [
    "**Possible Answer:**. There are multiple valid answers.  \n",
    "\n",
    "For one, Hessian matrices (2nd derivative matrices) are PSD and are thus convex.\n",
    "Convex functions guarantee that any local minimum is algo a global minimum.\n",
    "\n",
    "When using gradient descent, stepping down the gradient for such a function \n",
    "steps toward the minimum.\n",
    "\n",
    "**Grading note:** Ignore this problem.  We didn't cover where it appears in ML yet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fe94c6",
   "metadata": {},
   "source": [
    "17. **Orthogonal Matrices**\n",
    "a) Show that\n",
    "$$\n",
    "Q = \\begin{bmatrix} 0 & 1 \\\\ -1 & 0 \\end{bmatrix}\n",
    "$$\n",
    "is an orthogonal matrix.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e9a7ed",
   "metadata": {},
   "source": [
    "**Possible Answer:**\n",
    "\n",
    "A real square matrix $Q \\in \\mathbb{R}^{n \\times n}$ is orthogonal if:\n",
    "$Q^T Q = I$.\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix} 0 & 1 \\\\ -1 & 0 \\end{bmatrix}\n",
    "\\begin{bmatrix} 0 & -1 \\\\ 1 & 0 \\end{bmatrix}\n",
    "=\n",
    "\\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix}\n",
    "= I\n",
    "$$\n",
    "\n",
    "QED.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740a6e0d",
   "metadata": {},
   "source": [
    "b) Explain what it means geometrically when a matrix is orthogonal.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48362ea6",
   "metadata": {},
   "source": [
    "**Possible Answer:**\n",
    "\n",
    "The basis vectors represented by the matrix are at right angles and\n",
    "are all unit vectors. In other words, they form an orthonormal basis.\n",
    "As a linear transform, an orthogonal matrix preserves length\n",
    "and angles.  Orthogonal matrixes can perform rotations and \n",
    "reflections, but they cannot scale or shear. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
